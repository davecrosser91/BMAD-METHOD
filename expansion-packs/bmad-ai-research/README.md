# BMAD AI Research Expansion Pack ğŸ”¬

Transform BMAD-METHOD into a complete AI/ML research laboratory for academic paper development, experiment design, and scientific publication.

## Quick Start

**Local Development Install:**

```bash
# Install in existing project from local BMAD repo
cd your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select "bmad-ai-research" when prompted
```

**When Published (future):**

```bash
cd your-project
npx bmad-method install
# Select "bmad-ai-research"
```

Then activate any research agent:

```bash
# RESEARCH TEAM (11 agents - all from bmad-ai-research, fully autonomous!)
@research-lead              # Prof. Dr. Kunz - Team coordination & strategy
@research-assistant-web     # D. Freuzer - Web/blog/docs research
@research-assistant-arxiv   # H. Zoppel - ArXiv papers (MCP-dependent)
@research-assistant-kb      # A. Pilz - Knowledge base curation (Archon MCP)
@research-scientist         # Dr. Alex Kumar - Experiment design
@experiment-pm              # Dr. Chen Wei - Experiment planning & tasks
@experiment-architect       # Dr. Sofia Martinez - Code architecture design
@ml-engineer                # Jordan Lee - Code implementation (codebase/)
@data-analyst               # Dr. Maya Patel - Analysis (results/)
@research-writer            # Dr. Emma Wright - Paper writing (research-paper/)
@reproducibility-engineer   # Sam Rodriguez - Reproducibility validation
```

## Overview

The **AI Research Expansion Pack** adapts BMAD's proven agentic workflow to the unique demands of scientific research. While the core BMAD framework focuses on software product development, this pack specializes in the complete research lifecycle: from literature review through experiment execution to paper publication.

## ğŸ”„ Key Innovation: Three-Specialist Literature System

**NEW: Research Assistants Split into Three Specialists!**

Instead of one generalist, you now have **three specialized research assistants** working in parallel:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prof. Dr. Kunz (Research Lead)               â”‚
â”‚                    Coordinates all literature searches          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ D. Freuzer    â”‚  â”‚ H. Zoppel    â”‚  â”‚ A. Pilz      â”‚
      â”‚ Web Research  â”‚  â”‚ ArXiv Papers â”‚  â”‚ Knowledge Baseâ”‚
      â”‚ ğŸŒ            â”‚  â”‚ ğŸ“„           â”‚  â”‚ ğŸ“š           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                    â”‚                   â”‚
      Blogs, docs          Academic papers    Curated project
      Industry trends      Pre-prints         corpus with tags
      GitHub repos         Peer-reviewed      Organized papers
```

**The Iterative Brainstorm-Literature Loop (Enhanced):**

```
Research Lead (Prof. Dr. Kunz) â†’ Initial Brainstorming (10-20 questions)
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARALLEL LITERATURE SEARCH (All 3 Assistants Work Together)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ D. Freuzer  â†’ Web content, blogs, recent industry posts     â”‚
â”‚  â€¢ H. Zoppel   â†’ ArXiv papers (if MCP available)               â”‚
â”‚  â€¢ A. Pilz     â†’ Knowledge base tagged papers                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
Research Lead â†’ Synthesize findings, refine questions
                 â†“
        DEEPER DIVE (Targeted searches)
                 â†“
Research Lead â†’ Further refinement
                 â†“
        REPEAT 2-4 iterations until converged
                 â†“
   Well-Formed Research Questions + Identified Gaps
```

**Why Three Specialists?**

- âœ… **D. Freuzer (Web)**: Latest industry trends, practical implementations
- âœ… **H. Zoppel (ArXiv)**: Cutting-edge academic research, pre-prints
- âœ… **A. Pilz (KB)**: Your curated corpus, project-tagged papers
- âœ… **Parallel Search**: All three work simultaneously for comprehensive coverage
- âœ… **Prof. Dr. Kunz**: Synthesizes all findings, maintains objective focus

**Why This Matters:**

- âœ… Comprehensive coverage: Academic + Industry + Curated sources
- âœ… Ideas grounded in reality (not already fully solved)
- âœ… Questions become specific and testable
- âœ… Clear novelty and gaps identified upfront
- âœ… Saves months of pursuing dead ends
- âœ… Strong positioning for paper from day one

**ğŸ“– [See detailed iterative workflow guide](docs/ITERATIVE-RESEARCH-WORKFLOW.md)**

## Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PROF. DR. KUNZ (Research Lead)                     â”‚
â”‚                         Team Coordinator                               â”‚
â”‚  â€¢ Orchestrates all agents      â€¢ Maintains objective focus           â”‚
â”‚  â€¢ Synthesizes findings         â€¢ Makes final decisions               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â”‚                 â”‚                 â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ LITERATURE   â”‚  â”‚ EXPERIMENT   â”‚  â”‚  PUBLICATION    â”‚
   â”‚ SPECIALISTS  â”‚  â”‚    TEAM      â”‚  â”‚     TEAM        â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ D. Freuzer    â”‚        â”‚         â”‚ Research Writer â”‚
    â”‚ (Web) ğŸŒ      â”‚        â”‚         â”‚ Dr. Emma Wright â”‚
    â”‚ WebSearch     â”‚        â”‚         â”‚ research-paper/ â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚         â”‚ LaTeX + git     â”‚
    â”‚ H. Zoppel     â”‚        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ (ArXiv) ğŸ“„    â”‚        â”‚
    â”‚ ArXiv MCP     â”‚        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
    â”‚ A. Pilz       â”‚        â”‚
    â”‚ (KB) ğŸ“š       â”‚        â”‚
    â”‚ Archon MCP    â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Research Scientist     â”‚
                      â”‚ Dr. Alex Kumar         â”‚
                      â”‚ Experiment Design      â”‚
                      â”‚ Creates specifications â”‚
                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ experiment specs
                             â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  EXPERIMENT PLANNING  â”‚
                   â”‚  (bmad-ai-research)   â”‚
                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                   â”‚ 1. Experiment PM      â”‚
                   â”‚    Dr. Chen Wei       â”‚
                   â”‚    Creates dev plan   â”‚
                   â”‚         â†“             â”‚
                   â”‚ 2. Experiment Architectâ”‚
                   â”‚    Dr. Sofia Martinez â”‚
                   â”‚    Designs code arch  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ implementation tasks
                          â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ ML Engineer        â”‚
                 â”‚ Jordan Lee         â”‚
                 â”‚ codebase/          â”‚
                 â”‚ Implementation     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ outputs to
                          â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Data Analyst       â”‚
                 â”‚ Dr. Maya Patel     â”‚
                 â”‚ results/           â”‚
                 â”‚ Analysis & Viz     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Reproducibility Engineer (Sam Rodriguez)â”‚
        â”‚ Validates: codebase/ â†’ results/ â†’ paper/â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Pipeline (BMAD Core Integration):**

```
Research Scientist
    â†“
    Creates experiment specifications
    â†“
PM (Project Manager - BMAD Core)
    â†“
    Creates development plan & tasks
    â†“
Architect (Solution Architect - BMAD Core)
    â†“
    Designs implementation architecture
    â†“
ML Engineer
    â†“
    Implements in codebase/
```

**Folder Flow:**

```
codebase/           results/              research-paper/
   â†“                   â†“                        â†“
ML Engineer    â†’   Data Analyst    â†’    Research Writer
implements         analyzes               writes paper
experiments        creates figs           incorporates

                Reproducibility Engineer validates all â†’
```

## What Makes Research Different

| Software Development     | AI Research                                                                      |
| ------------------------ | -------------------------------------------------------------------------------- |
| Build working product    | Advance scientific knowledge                                                     |
| PRD â†’ Stories â†’ Code     | Proposal â†’ Experiments â†’ Paper                                                   |
| PM/Architect â†’ Developer | **Research Scientist â†’ PM/Architect â†’ ML Engineer** (Experiment Planning agents) |
| Features must work       | Experiments often fail (and that's okay)                                         |
| Deployed software        | Published paper + open code                                                      |
| QA checks functionality  | Peer review checks rigor                                                         |
| Single codebase          | **Three folders**: codebase/, results/, research-paper/                          |

## The Research Team

### 11 Specialized Research Agents (5 NEW!)

#### Literature Specialists (NEW: Split into 3!)

**ğŸŒ Web Research Specialist (D. Freuzer)** - @research-assistant-web

- Live web content, blogs, documentation
- Industry perspectives and trends
- GitHub repositories and implementations
- Recent posts and tutorials
- **Tools:** WebSearch, WebFetch
- **Commands:** `*search`, `*fetch`, `*search-docs`, `*search-github`, `*track-trends`

**ğŸ“„ ArXiv Specialist (H. Zoppel)** - @research-assistant-arxiv

- Academic pre-prints from arXiv
- Recent papers before peer review
- Author and category searches
- **MCP-Dependent:** Requires ArXiv MCP (gracefully fails if unavailable)
- **Tools:** ArXiv MCP (mcp**arxiv**search, mcp**arxiv**get_paper)
- **Commands:** `*search`, `*search-author`, `*search-category`, `*get-paper`

**ğŸ“š Knowledge Base Curator (A. Pilz)** - @research-assistant-kb

- Curated project knowledge base
- Tagged paper organization
- Full-text paper analysis
- Gap identification
- **Tools:** Archon MCP (rag_search_knowledge_base, rag_search_code_examples)
- **Commands:** `*set-tag`, `*sources`, `*search`, `*search-codes`, `*catalogue-paper`

#### Team Coordination

**ğŸ”¬ Research Lead (Prof. Dr. Kunz)** - @research-lead

- Team orchestration and coordination
- Literature search routing (directs D. Freuzer, H. Zoppel, A. Pilz)
- Research strategy and objectives
- Proposal development and validation
- Cross-agent synthesis
- Full project visibility (codebase/, results/, research-paper/)
- **Commands:** `*brainstorm`, `*create-proposal`, `*literature-review`, `*formulate-questions`

#### Experiment Team

**ğŸ§ª Research Scientist (Dr. Alex Kumar)** - @research-scientist

- Experimental design and methodology
- Works with Research Lead to construct experiments
- Creates specifications for PM/Architect â†’ ML Engineer pipeline
- Interprets results and refines experiments
- **Reads:** codebase/, results/
- **Commands:** `*create-architecture`, `*design-experiment`, `*interpret-results`

**âš™ï¸ ML Engineer (Jordan Lee)** - @ml-engineer

- Code implementation in **codebase/** folder
- Receives tasks from PM/Architect (BMAD core workflows)
- Implements experiments, baselines, novel methods
- Runs experiments, outputs to results/
- **Primary workspace:** codebase/
- **Commands:** `*implement-experiment`, `*implement-baseline`, `*run-ablation`

**ğŸ“Š Data Analyst (Dr. Maya Patel)** - @data-analyst

- Dataset preparation in **codebase/data/**
- Statistical analysis and visualization
- Creates publication-quality figures in **results/**
- Significance testing and error analysis
- **Workspaces:** codebase/data/, results/
- **Commands:** `*prepare-dataset`, `*analyze-results`, `*create-figures`, `*test-significance`

#### Publication Team

**âœï¸ Research Writer (Dr. Emma Wright)** - @research-writer

- Paper writing in **research-paper/** folder
- LaTeX editing and formatting
- Git/Overleaf synchronization
- Incorporates results/ into paper
- **Primary workspace:** research-paper/
- **Tools:** LaTeX, git
- **Commands:** `*create-paper`, `*draft-abstract`, `*draft-introduction`, `*prepare-submission`

**ğŸ” Reproducibility Engineer (Sam Rodriguez)** - @reproducibility-engineer

- Cross-folder validation (codebase/ â†’ results/ â†’ research-paper/)
- Ensures experiments are reproducible
- Code release preparation
- Documentation and containerization
- **Validates:** All folders
- **Commands:** `*verify-reproducibility`, `*prepare-release`, `*create-dockerfile`

## Complete Research Workflow (UPDATED!)

### ğŸ“ Folder Structure

All research artifacts are organized into three main folders:

```
your-research-project/
â”œâ”€â”€ codebase/              # ML Engineer's primary workspace
â”‚   â”œâ”€â”€ data/              # Datasets (Data Analyst + ML Engineer)
â”‚   â”œâ”€â”€ src/               # Experiment code
â”‚   â”œâ”€â”€ configs/           # Hyperparameters
â”‚   â”œâ”€â”€ tests/             # Unit tests
â”‚   â””â”€â”€ README.md          # Setup & reproduction guide
â”‚
â”œâ”€â”€ results/               # Data Analyst's primary output
â”‚   â”œâ”€â”€ figures/           # Publication-quality visualizations
â”‚   â”œâ”€â”€ tables/            # LaTeX-formatted tables
â”‚   â”œâ”€â”€ analysis/          # Statistical test results
â”‚   â””â”€â”€ metrics/           # Experimental metrics
â”‚
â””â”€â”€ research-paper/        # Research Writer's workspace (LaTeX + git)
    â”œâ”€â”€ main.tex           # Main paper file
    â”œâ”€â”€ sections/          # Paper sections
    â”œâ”€â”€ figures/           # Figures copied from results/
    â”œâ”€â”€ references.bib     # Bibliography
    â””â”€â”€ .git/              # Git repository (syncs with Overleaf)
```

### Phase 1: Planning - THREE-SPECIALIST LITERATURE SYSTEM

```
Prof. Dr. Kunz (Research Lead)
   â”‚
   â”œâ”€â†’ Initial Brainstorming (10-20 questions)
   â”‚
   â”œâ”€â†’ PARALLEL LITERATURE SEARCH â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”œâ”€â†’ D. Freuzer (Web):    Blogs, docs, GitHub   â”‚
   â”‚   â”œâ”€â†’ H. Zoppel (ArXiv):   Academic pre-prints   â”‚  Iteration 1
   â”‚   â””â”€â†’ A. Pilz (KB):        Tagged knowledge base â”‚
   â”‚                                                    â”‚
   â”œâ”€â†’ Synthesize all findings                         â”‚
   â”‚                                                    â”‚
   â”œâ”€â†’ Refine research questions                       â”‚
   â”‚                                                    â”‚
   â””â”€â†’ DEEPER DIVE (targeted searches) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ REPEAT 2-4 iterations until converged
       â”‚
       â”œâ”€â†’ Identify Gaps & Novel Contributions
       â”‚
       â”œâ”€â†’ Create Research Proposal
       â”‚
       â””â”€â†’ Research Scientist: Experimental Architecture
           â”‚
           â””â”€â†’ Prof. Dr. Kunz: Validation
```

**Outputs:**

- `research-brainstorming-session-results.md` (Research Lead)
- `literature-review.md` (All 3 assistants' findings synthesized)
- `research-proposal.md` (Research Lead)
- `experimental-architecture.md` (Research Scientist)

**Key Innovation:** Three specialists cover all sources (web + academic + curated) in parallel!

### Phase 2: Experimentation - BMAD CORE INTEGRATION

```
Research Scientist (Dr. Alex Kumar)
   â”‚
   â”œâ”€â†’ Design Experiment Specifications
   â”‚   â€¢ Methodology details
   â”‚   â€¢ Baselines to implement
   â”‚   â€¢ Evaluation metrics
   â”‚   â€¢ Success criteria
   â”‚
   â””â”€â†’ EXPERIMENT PLANNING WORKFLOW
       â”‚
       â”œâ”€â†’ Project Manager (@experiment-pm from bmad-ai-research)
       â”‚   â”‚
       â”‚   â”œâ”€â†’ Creates development plan
       â”‚   â”œâ”€â†’ Breaks down experiment into tasks
       â”‚   â”œâ”€â†’ Defines implementation milestones
       â”‚   â”‚
       â”‚   â””â”€â†’ Solution Architect (@experiment-architect from bmad-ai-research)
       â”‚       â”‚
       â”‚       â”œâ”€â†’ Designs code architecture
       â”‚       â”œâ”€â†’ Plans module structure (codebase/src/)
       â”‚       â”œâ”€â†’ Defines interfaces and APIs
       â”‚       â”‚
       â”‚       â””â”€â†’ ML Engineer (Jordan Lee - codebase/)
       â”‚           â”‚
       â”‚           â”œâ”€â†’ Implement experiment code
       â”‚           â”œâ”€â†’ Implement baselines
       â”‚           â”œâ”€â†’ Setup experiment tracking
       â”‚           â”‚
       â”‚           â””â”€â†’ Run experiments â†’ outputs to results/
       â”‚               â”‚
       â”‚               â””â”€â†’ Data Analyst (Dr. Maya Patel - results/)
       â”‚                   â”‚
       â”‚                   â”œâ”€â†’ Prepare datasets (codebase/data/)
       â”‚                   â”œâ”€â†’ Statistical analysis
       â”‚                   â”œâ”€â†’ Create figures (results/figures/)
       â”‚                   â”œâ”€â†’ Format tables (results/tables/)
       â”‚                   â”‚
       â”‚                   â””â”€â†’ Research Scientist: Interpret Results
       â”‚                       â”‚
       â”‚                       â””â”€â†’ If needed: Refine & iterate
```

**Experiment Planning Integration:**

- **Research Scientist** creates high-level experiment specs
- **PM** (from bmad-ai-research) plans development workflow
- **Architect** (from bmad-ai-research) designs implementation structure
- **ML Engineer** executes implementation

**Folder Flow:**

- Code lives in: `codebase/`
- Data lives in: `codebase/data/`
- Results output to: `results/`

**Outputs:**

- Development plan (PM)
- Architecture design (Architect)
- Experiment code (`codebase/`)
- Trained models (not version controlled)
- Analysis artifacts (`results/`)

### Phase 3: Writing - LATEX + GIT + OVERLEAF

```
Research Writer (research-paper/)
   â”‚
   â”œâ”€â†’ git pull (sync from Overleaf)
   â”‚
   â”œâ”€â†’ Create Paper Outline (main.tex, sections/)
   â”‚
   â”œâ”€â†’ Copy figures from results/ â†’ research-paper/figures/
   â”‚
   â”œâ”€â†’ Draft All Sections
   â”‚   â”œâ”€â†’ Abstract
   â”‚   â”œâ”€â†’ Introduction
   â”‚   â”œâ”€â†’ Related Work (coordinate with A. Pilz for citations)
   â”‚   â”œâ”€â†’ Methodology (coordinate with Research Scientist)
   â”‚   â”œâ”€â†’ Experiments (incorporate from results/)
   â”‚   â””â”€â†’ Conclusion
   â”‚
   â”œâ”€â†’ git commit -m "Draft complete"
   â”œâ”€â†’ git push (sync to Overleaf)
   â”‚
   â”œâ”€â†’ Prof. Dr. Kunz: Review Draft
   â”‚
   â”œâ”€â†’ Research Writer: Revise & Polish
   â”‚
   â”œâ”€â†’ Format for Target Venue (NeurIPS/ICML/ICLR/etc.)
   â”‚
   â””â”€â†’ git push (final version synced)
```

**Folder Flow:**

- Paper lives in: `research-paper/`
- Reads figures from: `results/`
- Git syncs with: Overleaf

**Outputs:**

- Complete LaTeX paper (`research-paper/`)
- Submission-ready PDF

### Phase 4: Publication - REPRODUCIBILITY VALIDATION

```
Reproducibility Engineer
   â”‚
   â”œâ”€â†’ Validate codebase/
   â”‚   â”œâ”€â†’ Check seeds, dependencies, README
   â”‚   â””â”€â†’ Verify experiments can be re-run
   â”‚
   â”œâ”€â†’ Validate results/
   â”‚   â””â”€â†’ Confirm figures/metrics match paper claims
   â”‚
   â”œâ”€â†’ Validate research-paper/
   â”‚   â””â”€â†’ Ensure all claims backed by results/
   â”‚
   â”œâ”€â†’ Create Documentation
   â”‚   â”œâ”€â†’ codebase/README.md
   â”‚   â”œâ”€â†’ codebase/REPRODUCE.md
   â”‚   â””â”€â†’ Dockerfile/environment.yml
   â”‚
   â”œâ”€â†’ Prepare Code Release
   â”‚   â”œâ”€â†’ Clean codebase/ for public
   â”‚   â”œâ”€â†’ Add LICENSE
   â”‚   â””â”€â†’ Remove sensitive data
   â”‚
   â””â”€â†’ Prof. Dr. Kunz: Final Validation
       â”‚
       â””â”€â†’ SUBMIT to Conference/Journal
```

**Cross-Folder Validation:**

- `codebase/` â†’ Can reproduce â†’ `results/`
- `results/` â†’ Matches claims in â†’ `research-paper/`

**Outputs:**

- Submitted paper
- Public code repository (GitHub)
- Reproducibility artifacts

## Key Documents

### Research-Specific Templates

**Research Proposal** (`research-proposal-tmpl.yaml`)

- Problem statement and motivation
- Research questions and hypotheses
- Proposed approach
- Expected contributions
- Timeline and resources

**Experimental Architecture** (`experimental-architecture-tmpl.yaml`)

- Model architecture specifications
- Training procedures
- Baseline implementations
- Evaluation protocols
- Reproducibility specifications

**Paper Outline** (`paper-outline-tmpl.yaml`)

- Complete paper structure
- Section-by-section planning
- Figure and table planning
- Page budget allocation

**Experiment Specification** (`experiment-spec-tmpl.yaml`)

- Hypothesis to test
- Methodology details
- Implementation plan
- Success criteria
- Analysis approach

**Literature Review** (`literature-review-tmpl.yaml`)

- Thematic organization
- Key papers analysis
- Research gaps identification
- Positioning statement

**Reproducibility Checklist** (`reproducibility-checklist-tmpl.yaml`)

- Code reproducibility checks
- Environment setup validation
- Data pipeline verification
- Results validation

## Installation & Setup

### Step 1: Install Expansion Pack

**Option A: From Published Package (when available):**

```bash
cd your-project
npx bmad-method install
# Select "bmad-ai-research" when prompted
```

**Option B: Local Development (current):**

Since this expansion pack is in development and not yet published:

```bash
# 1. Clone or navigate to BMAD-METHOD repo
cd /path/to/BMAD-METHOD

# 2. Install in your project from local source
cd /path/to/your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select "bmad-ai-research" when prompted

# OR copy directly to your project
cp -r /path/to/BMAD-METHOD/expansion-packs/bmad-ai-research \
      /path/to/your-project/.bmad-ai-research
```

**Fresh research project:**

```bash
mkdir my-research-project && cd my-research-project
# Use one of the methods above
```

### Step 2: (Optional) Configure Archon MCP for Literature Search

If you want automated literature search via the Research Assistant:

1. **Ensure Archon MCP is running** in your IDE (should already be configured)
2. **Add research papers to knowledge base** with project-specific tags
3. **Use Research Assistant** with your project tag:

```bash
@research-assistant
*set-tag "ml-research"     # Your project tag
*sources                   # List available sources
*search "attention mechanisms"  # Search papers
```

**No Archon MCP?** The Research Assistant will guide you to manual literature searches instead.

### Step 3: Start Your First Research Project

```bash
# 1. Brainstorm research questions
@research-lead
*brainstorm "your research topic"

# 2. Search literature (if Archon MCP available)
@research-assistant
*search "relevant keywords"

# 3. Iterate until converged (2-4 cycles)

# 4. Create proposal
@research-lead
*create-proposal
```

**ğŸ“– Full setup guide:** [SETUP-CHECKLIST.md](SETUP-CHECKLIST.md)

## Usage Examples

### Starting a New Research Project (Three-Specialist System)

```bash
# Step 1: Brainstorm initial questions
@research-lead
*brainstorm "efficient attention mechanisms for transformers"
# â†’ Prof. Dr. Kunz generates 10-20 research questions

# Step 2: Parallel literature search (all three specialists)
# The Research Lead coordinates this, but you can also invoke directly:

@research-assistant-web      # D. Freuzer
*search "efficient attention mechanisms 2024"
# â†’ Searches blogs, documentation, GitHub
# â†’ Finds: HuggingFace blog posts, PyTorch tutorials, recent implementations

@research-assistant-arxiv    # H. Zoppel (if MCP available)
*search "efficient attention transformers"
# â†’ Searches arXiv pre-prints
# â†’ Finds: FlashAttention-3, recent academic papers

@research-assistant-kb       # A. Pilz
*set-tag "transformer-research"
*search "attention mechanisms"
# â†’ Searches your curated knowledge base
# â†’ Finds: Tagged papers in your project corpus

# Step 3: Prof. Dr. Kunz synthesizes all findings
@research-lead
*formulate-questions
# â†’ Refines questions based on gaps from ALL THREE sources

# Step 4: Deeper targeted dive (iteration 2)
@research-assistant-web
*search-github "flash attention implementation"

@research-assistant-arxiv
*search-author "Dao"  # FlashAttention author

@research-assistant-kb
*identify-gaps
# â†’ What's missing from KB that should be added?

# Repeat iterations 2-4 times until converged

# Step 5: Create formal proposal
@research-lead
*create-proposal
# â†’ Creates research-proposal.yaml

# Step 6: Design experiments
@research-scientist
*create-architecture
*design-experiment
# â†’ Creates detailed experiment specifications
```

### Running Experiments (with BMAD Core PM/Architect)

```bash
# Step 1: Prepare data
@data-analyst
*prepare-dataset
# â†’ Processes data in codebase/data/
# â†’ Validates and documents datasets

# Step 2: Development Planning (BMAD Core Workflow)
@experiment-pm  # From bmad-core package
# Takes Research Scientist's experiment specs
# â†’ Creates development plan
# â†’ Breaks down into implementation tasks
# â†’ Defines milestones

@experiment-architect  # From bmad-core package
# Takes PM's development plan
# â†’ Designs code architecture
# â†’ Plans codebase/src/ module structure
# â†’ Defines interfaces and data flow

# Step 3: Implementation (codebase/)
@ml-engineer
*implement-experiment
# â†’ Follows Architect's design
# â†’ Writes code in codebase/src/
# â†’ Implements experiment logic

*implement-baseline
# â†’ Codes baseline methods

*setup-tracking
# â†’ wandb/tensorboard integration

# Step 4: Execute experiments
@ml-engineer
*run-ablation
# â†’ Runs experiments with proper seeds
# â†’ Outputs metrics/logs to results/

# Step 4: Analyze results (results/)
@data-analyst
*analyze-results
# â†’ Reads from results/, performs statistical tests
# â†’ Creates figures in results/figures/
# â†’ Formats tables in results/tables/

*create-figures
# â†’ Publication-quality plots (300 DPI, LaTeX fonts)

# Step 5: Interpret findings
@research-scientist
*interpret-results
# â†’ Analyzes results/ against hypotheses
# â†’ Suggests refinements if needed
```

### Writing Paper (research-paper/ with LaTeX + git)

```bash
# Step 1: Setup paper folder
@research-writer
# â†’ git pull (sync from Overleaf if already exists)
*create-paper
# â†’ Creates main.tex, sections/, references.bib in research-paper/

# Step 2: Copy figures from results/
# â†’ Manually or via Research Writer:
# cp results/figures/* research-paper/figures/

# Step 3: Draft sections (all in research-paper/)
@research-writer
*draft-abstract
# â†’ Writes abstract in sections/abstract.tex

*draft-introduction
# â†’ Includes motivation, contributions

*draft-related-work
# â†’ Coordinates with @research-assistant-kb (A. Pilz) for citations

*draft-methodology
# â†’ Coordinates with @research-scientist for technical details

*draft-experiments
# â†’ Incorporates results/ (figures, tables, metrics)

*draft-conclusion
# â†’ Summary, impact, future work

# Step 4: Git sync
# â†’ Research Writer commits and pushes
# git add . && git commit -m "Complete draft" && git push
# â†’ Syncs to Overleaf automatically

# Step 5: Review
@research-lead
# â†’ Prof. Dr. Kunz reviews on Overleaf
# â†’ Provides feedback

# Step 6: Revise and submit
@research-writer
# â†’ git pull (get latest from Overleaf)
*revise-paper
*prepare-submission
# â†’ Formats for NeurIPS/ICML/ICLR/etc.
# git push (final version)
```

### Preparing Code Release (Cross-folder validation)

```bash
@reproducibility-engineer

# Step 1: Validate codebase/
*verify-reproducibility
# â†’ Check seeds set correctly
# â†’ Verify requirements.txt/environment.yml complete
# â†’ Test that codebase/ experiments can be re-run
# â†’ Ensure codebase/README.md is comprehensive

# Step 2: Validate results/
# â†’ Confirm figures match paper claims
# â†’ Check metrics in results/ match research-paper/
# â†’ Verify all paper figures came from results/

# Step 3: Validate research-paper/
# â†’ Ensure all claims backed by results/
# â†’ Check figure numbers match
# â†’ Verify no orphaned claims

# Step 4: Create documentation
*create-readme
# â†’ Generates codebase/README.md
# â†’ Creates codebase/REPRODUCE.md (step-by-step guide)

*create-dockerfile
# â†’ Docker/Singularity for reproducibility

# Step 5: Prepare for public release
*prepare-release
# â†’ Clean codebase/ (remove secrets, internal paths)
# â†’ Add LICENSE file
# â†’ Prepare GitHub repository
# â†’ Final validation: can a stranger reproduce results/?

# Step 6: Final sign-off
# â†’ Prof. Dr. Kunz reviews all three folders
# â†’ Submits paper + code
```

## Best Practices

### Reproducibility First

- Set all random seeds from day one
- Version control everything (code, configs, not models)
- Document as you go, not retrospectively
- Use experiment tracking (wandb, tensorboard)

### Embrace Failure

- Most experiments fail - that's research
- Failed experiments teach what doesn't work
- Document failures to avoid repeating them
- Pivot based on what you learn

### Statistical Rigor

- Always run multiple seeds (3-5 minimum)
- Report mean Â± standard deviation
- Perform significance testing
- Compare fairly against strong baselines

### Honest Science

- Report what you find, not what you hoped
- Acknowledge limitations explicitly
- Give proper credit to related work
- Don't cherry-pick favorable results

## Typical Timeline

- **Planning Phase:** 1-2 weeks
- **Implementation:** 2-4 weeks
- **Experimentation:** 2-6+ weeks (variable!)
- **Analysis:** 1-2 weeks
- **Writing:** 2-4 weeks
- **Revision (if needed):** 1-4 weeks

**Total:** 3-6 months for conference paper

## Target Venues

This pack helps you prepare papers for:

**Top ML Conferences:**

- NeurIPS, ICML, ICLR

**Top Vision Conferences:**

- CVPR, ICCV, ECCV

**Top NLP Conferences:**

- ACL, EMNLP, NAACL

**And many others** (specialized venues for robotics, data mining, etc.)

## What's Included

### ğŸ“ Directory Structure

```
bmad-ai-research/
â”œâ”€â”€ agents/                 # 9 specialized research agents (3 NEW!)
â”‚   â”œâ”€â”€ research-lead.md                    # Prof. Dr. Kunz (team coordinator)
â”‚   â”œâ”€â”€ research-assistant-web.md           # NEW! D. Freuzer (web research)
â”‚   â”œâ”€â”€ research-assistant-arxiv.md         # NEW! H. Zoppel (arXiv papers)
â”‚   â”œâ”€â”€ research-assistant-kb.md            # NEW! A. Pilz (knowledge base)
â”‚   â”œâ”€â”€ research-scientist.md               # Dr. Alex Kumar (experiment design)
â”‚   â”œâ”€â”€ ml-engineer.md                      # Jordan Lee (codebase/ implementation)
â”‚   â”œâ”€â”€ data-analyst.md                     # Dr. Maya Patel (results/ analysis)
â”‚   â”œâ”€â”€ research-writer.md                  # Dr. Emma Wright (research-paper/ writing)
â”‚   â””â”€â”€ reproducibility-engineer.md         # Sam Rodriguez (validation)
â”œâ”€â”€ agent-teams/           # Pre-configured research team
â”‚   â””â”€â”€ research-team.yaml                  # UPDATED: 3 literature specialists
â”œâ”€â”€ templates/             # 6 research document templates
â”œâ”€â”€ workflows/             # 2 complete research workflows
â”œâ”€â”€ tasks/                 # 3 research-specific tasks
â”œâ”€â”€ checklists/            # Implementation & reproducibility checklists
â”œâ”€â”€ data/                  # Research knowledge base
â”œâ”€â”€ docs/                  # Setup and integration guides
â”‚   â”œâ”€â”€ ARCHON-MCP-INTEGRATION.md
â”‚   â””â”€â”€ ITERATIVE-RESEARCH-WORKFLOW.md
â””â”€â”€ config.yaml            # Pack configuration
```

### ğŸ¯ Key Features

**ğŸ†• NEW IN THIS VERSION:**

- **Three-Specialist Literature System**: Web (D. Freuzer) + ArXiv (H. Zoppel) + KB (A. Pilz) working in parallel
- **Comprehensive Source Coverage**: Industry trends + Academic papers + Curated corpus
- **Folder-Based Workflow**: Organized structure (codebase/, results/, research-paper/)
- **BMAD Core Integration**: Full workflow with Project Manager + Solution Architect
  - Research Scientist designs experiments
  - PM (bmad-core) plans development
  - Architect (bmad-core) designs implementation
  - ML Engineer executes in codebase/
- **LaTeX + Git + Overleaf**: Professional paper writing with version control
- **Cross-Folder Validation**: Reproducibility Engineer ensures pipeline integrity

**CORE FEATURES:**

- **Iterative Brainstorming**: Proven 2-4 cycle loop between ideation and literature
- **Hypothesis-Focused**: Every experiment tests specific hypotheses
- **Reproducibility-First**: Comprehensive reproducibility infrastructure
- **Publication-Ready**: Templates match conference/journal requirements
- **Statistically Rigorous**: Built-in statistical testing guidance
- **Peer Review Aware**: Anticipates reviewer concerns
- **Team Coordination**: Prof. Dr. Kunz orchestrates entire research team

## Documentation

- **ğŸ“š Setup Guide**: [SETUP-CHECKLIST.md](SETUP-CHECKLIST.md) - Complete installation and setup
- **ğŸ”— Archon MCP Integration**: [docs/ARCHON-MCP-INTEGRATION.md](docs/ARCHON-MCP-INTEGRATION.md) - Literature search setup
- **ğŸ”„ Iterative Workflow**: [docs/ITERATIVE-RESEARCH-WORKFLOW.md](docs/ITERATIVE-RESEARCH-WORKFLOW.md) - Brainstorm-literature loop
- **ğŸ“– Research Knowledge Base**: [data/research-kb.md](data/research-kb.md) - Best practices guide
- **âš™ï¸ Full Workflow**: [workflows/research-paper-full.yaml](workflows/research-paper-full.yaml) - End-to-end process
- **ğŸ”¬ Experiment Iteration**: [workflows/experiment-iteration.yaml](workflows/experiment-iteration.yaml) - Focused experiment cycle

## Differences from Core BMAD

| Core BMAD                       | AI Research Pack                                                        |
| ------------------------------- | ----------------------------------------------------------------------- |
| PRD                             | Research Proposal                                                       |
| Architecture                    | Experimental Architecture                                               |
| User Stories                    | Experiment Specifications                                               |
| **PM/Architect plan features**  | **Research Scientist â†’ PM/Architect â†’ ML Engineer** (fully autonomous!) |
| Dev implements features         | ML Engineer implements experiments                                      |
| QA checks functionality         | Reproducibility Engineer checks reproducibility                         |
| Product release                 | Paper publication + code release                                        |
| Single codebase                 | Three folders: codebase/, results/, research-paper/                     |
| 1 generalist research assistant | 3 specialist research assistants (Web, ArXiv, KB)                       |

## Common Research Pitfalls Avoided

âœ… **Fair baseline comparisons** - Templates enforce equal tuning effort
âœ… **Statistical significance** - Built-in significance testing
âœ… **Reproducibility** - Comprehensive checklists from day one
âœ… **Clear contributions** - Structured proposal and paper templates
âœ… **Honest limitations** - Templates prompt for limitation discussion
âœ… **Proper attribution** - Literature review integrated throughout

## Success Stories

Research conducted with structured workflows like this:

- Higher acceptance rates (fewer desk rejects)
- Faster iteration (clear experiment specifications)
- Better reproducibility (checklist-driven development)
- Easier collaboration (standardized documents)
- Reduced reviewer concerns (comprehensive methodology)

## Contributing

Found a bug? Have suggestions? Want to add features?

- Open an issue in the main BMAD repository
- Contribute research-specific improvements
- Share your published papers using this pack!

## License

MIT License - Same as core BMAD-METHOD

## Acknowledgments

Built on the BMAD-METHODâ„¢ framework by BMad Code, LLC.

Designed for researchers who want to:

- Conduct rigorous, reproducible research
- Navigate the publication process systematically
- Collaborate effectively on research projects
- Advance their field with solid contributions

---

## Quick Links

- ğŸ“– [Setup Checklist](SETUP-CHECKLIST.md) - Get started in minutes
- ğŸ”— [Archon MCP Setup](docs/ARCHON-MCP-INTEGRATION.md) - Enable automated literature search
- ğŸ”„ [Iterative Workflow](docs/ITERATIVE-RESEARCH-WORKFLOW.md) - Master the brainstorm-literature loop
- âš¡ [Quick Reference](QUICK-FIX.md) - Common commands and patterns

---

**Ready to start your research journey?**

```bash
# Install the pack (local development)
cd /path/to/your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select: bmad-ai-research

# OR when published:
# npx bmad-method install
# Select: bmad-ai-research

# Start researching!
@research-lead
*brainstorm "your research topic"

# Parallel literature search (three specialists)
@research-assistant-web      # D. Freuzer: Web/blogs
*search "your topic 2024"

@research-assistant-arxiv    # H. Zoppel: ArXiv (if MCP available)
*search "your topic"

@research-assistant-kb       # A. Pilz: Knowledge base
*set-tag "your-project"
*search "your topic"
```

**Questions?**

- ğŸ“š Check the [research knowledge base](data/research-kb.md)
- ğŸ’¬ Join the [BMAD Discord](https://discord.gg/gk8jAdXWmj)
- ğŸ› Report issues on [GitHub](https://github.com/bmadcode/bmad-method/issues)

---

ğŸ”¬ **Good luck with your research!** ğŸ“ŠğŸ“

_Built with â¤ï¸ for researchers who want rigorous, reproducible, and publishable AI research._
