# BMAD AI Research Expansion Pack ğŸ”¬

Transform BMAD-METHOD into a complete AI/ML research laboratory for academic paper development, experiment design, and scientific publication.

## Quick Start

**Local Development Install:**

```bash
# Install in existing project from local BMAD repo
cd your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select "bmad-ai-research" when prompted
```

**When Published (future):**

```bash
cd your-project
npx bmad-method install
# Select "bmad-ai-research"
```

**MCP Server Setup (Required for Full Features):**

This expansion pack integrates with two MCP servers for enhanced capabilities:

1. **Archon MCP** - Project management, knowledge base, task tracking (see [Archon integration docs](docs/ARCHON-MCP-INTEGRATION.md))
2. **wandb MCP** - Experiment tracking and results analysis

```bash
# Install wandb MCP server
npm install -g @wandb/mcp-server
# or
pip install wandb-mcp

# Configure in your Claude desktop config
# Add to claude_desktop_config.json:
{
  "mcpServers": {
    "wandb": {
      "command": "wandb-mcp",
      "env": {
        "WANDB_API_KEY": "your_api_key_from_wandb.ai/authorize"
      }
    }
  }
}
```

Then activate any research agent:

```bash
# RESEARCH TEAM (11 agents - all from bmad-ai-research, fully autonomous!)
@research-lead              # Prof. Dr. Kunz - Team coordination & strategy
@research-assistant-web     # D. Freuzer - Web/blog/docs research
@research-assistant-arxiv   # H. Zoppel - ArXiv papers (MCP-dependent)
@research-assistant-kb      # A. Pilz - Knowledge base curation (Archon MCP)
@research-scientist         # Dr. Alex Kumar - Experiment design
@experiment-pm              # Dr. Chen Wei - Experiment planning & tasks
@experiment-architect       # Dr. Sofia Martinez - Code architecture design
@ml-engineer                # Jordan Lee - Code implementation (codebase/)
@data-analyst               # Dr. Maya Patel - Analysis (results/)
@research-writer            # Dr. Gatsby Sarihuela - Paper writing (research-paper/)
@reproducibility-engineer   # Sam Rodriguez - Reproducibility validation
```

## Overview

The **AI Research Expansion Pack** adapts BMAD's proven agentic workflow to the unique demands of scientific research. While the core BMAD framework focuses on software product development, this pack specializes in the complete research lifecycle: from literature review through experiment execution to paper publication.

## ğŸ”„ Key Innovation: Three-Specialist Literature System

**NEW: Research Assistants Split into Three Specialists!**

Instead of one generalist, you now have **three specialized research assistants** working in parallel:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prof. Dr. Kunz (Research Lead)               â”‚
â”‚                    Coordinates all literature searches          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ D. Freuzer    â”‚  â”‚ H. Zoppel    â”‚  â”‚ A. Pilz      â”‚
      â”‚ Web Research  â”‚  â”‚ ArXiv Papers â”‚  â”‚ Knowledge Baseâ”‚
      â”‚ ğŸŒ            â”‚  â”‚ ğŸ“„           â”‚  â”‚ ğŸ“š           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                    â”‚                   â”‚
      Blogs, docs          Academic papers    Curated project
      Industry trends      Pre-prints         corpus with tags
      GitHub repos         Peer-reviewed      Organized papers
```

**The Iterative Brainstorm-Literature Loop (Enhanced):**

```
Research Lead (Prof. Dr. Kunz) â†’ Initial Brainstorming (10-20 questions)
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARALLEL LITERATURE SEARCH (All 3 Assistants Work Together)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ D. Freuzer  â†’ Web content, blogs, recent industry posts     â”‚
â”‚  â€¢ H. Zoppel   â†’ ArXiv papers (if MCP available)               â”‚
â”‚  â€¢ A. Pilz     â†’ Knowledge base tagged papers                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
Research Lead â†’ Synthesize findings, refine questions
                 â†“
        DEEPER DIVE (Targeted searches)
                 â†“
Research Lead â†’ Further refinement
                 â†“
        REPEAT 2-4 iterations until converged
                 â†“
   Well-Formed Research Questions + Identified Gaps
```

**Why Three Specialists?**

- âœ… **D. Freuzer (Web)**: Latest industry trends, practical implementations
- âœ… **H. Zoppel (ArXiv)**: Cutting-edge academic research, pre-prints
- âœ… **A. Pilz (KB, Archron)**: Your curated corpus, project-tagged papers
- âœ… **Parallel Search**: All three work simultaneously for comprehensive coverage
- âœ… **Prof. Dr. Kunz**: Synthesizes all findings, maintains objective focus

**Why This Matters:**

- âœ… Comprehensive coverage: Academic + Industry + Curated sources
- âœ… Ideas grounded in reality (not already fully solved)
- âœ… Questions become specific and testable
- âœ… Clear novelty and gaps identified upfront
- âœ… Saves months of pursuing dead ends
- âœ… Strong positioning for paper from day one

**ğŸ“– [See detailed iterative workflow guide](docs/ITERATIVE-RESEARCH-WORKFLOW.md)**

## Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PROF. DR. KUNZ (Research Lead)                     â”‚
â”‚                         Team Coordinator                               â”‚
â”‚  â€¢ Orchestrates all agents      â€¢ Maintains objective focus           â”‚
â”‚  â€¢ Synthesizes findings         â€¢ Makes final decisions               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â”‚                 â”‚                 â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ LITERATURE   â”‚  â”‚ EXPERIMENT   â”‚  â”‚  PUBLICATION    â”‚
   â”‚ SPECIALISTS  â”‚  â”‚    TEAM      â”‚  â”‚     TEAM        â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ D. Freuzer    â”‚        â”‚         â”‚ Research Writer â”‚
    â”‚ (Web) ğŸŒ      â”‚        â”‚         â”‚ Dr. Gatsby Sarihuela â”‚
    â”‚ WebSearch     â”‚        â”‚         â”‚ research-paper/ â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚         â”‚ LaTeX + git     â”‚
    â”‚ H. Zoppel     â”‚        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ (ArXiv) ğŸ“„    â”‚        â”‚
    â”‚ ArXiv MCP     â”‚        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
    â”‚ A. Pilz       â”‚        â”‚
    â”‚ (KB) ğŸ“š       â”‚        â”‚
    â”‚ Archon MCP    â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Research Scientist     â”‚
                      â”‚ Dr. Alex Kumar         â”‚
                      â”‚ Experiment Design      â”‚
                      â”‚ Creates specifications â”‚
                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ experiment specs
                             â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  EXPERIMENT PLANNING  â”‚
                   â”‚  (bmad-ai-research)   â”‚
                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                   â”‚ 1. Experiment PM      â”‚
                   â”‚    Dr. Chen Wei       â”‚
                   â”‚    Creates dev plan   â”‚
                   â”‚         â†“             â”‚
                   â”‚ 2. Experiment Architectâ”‚
                   â”‚    Dr. Sofia Martinez â”‚
                   â”‚    Designs code arch  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ implementation tasks
                          â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ ML Engineer        â”‚
                 â”‚ Jordan Lee         â”‚
                 â”‚ codebase/          â”‚
                 â”‚ Implementation     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ outputs to
                          â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Data Analyst       â”‚
                 â”‚ Dr. Maya Patel     â”‚
                 â”‚ results/           â”‚
                 â”‚ Analysis & Viz     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Reproducibility Engineer (Sam Rodriguez)â”‚
        â”‚ Validates: codebase/ â†’ results/ â†’ paper/â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Pipeline (BMAD Core Integration):**

```
Research Scientist
    â†“
    Creates experiment specifications
    â†“
PM (Project Manager - BMAD Core)
    â†“
    Creates development plan & tasks
    â†“
Architect (Solution Architect - BMAD Core)
    â†“
    Designs implementation architecture
    â†“
ML Engineer
    â†“
    Implements in codebase/
```

**Folder Flow:**

```
codebase/           results/              research-paper/
   â†“                   â†“                        â†“
ML Engineer    â†’   Data Analyst    â†’    Research Writer
implements         analyzes               writes paper
experiments        creates figs           incorporates

                Reproducibility Engineer validates all â†’
```

## What Makes Research Different

| Software Development     | AI Research                                                                      |
| ------------------------ | -------------------------------------------------------------------------------- |
| Build working product    | Advance scientific knowledge                                                     |
| PRD â†’ Stories â†’ Code     | Proposal â†’ Experiments â†’ Paper                                                   |
| PM/Architect â†’ Developer | **Research Scientist â†’ PM/Architect â†’ ML Engineer** (Experiment Planning agents) |
| Features must work       | Experiments often fail (and that's okay)                                         |
| Deployed software        | Published paper + open code                                                      |
| QA checks functionality  | Peer review checks rigor                                                         |
| Single codebase          | **Three folders**: codebase/, results/, research-paper/                          |

## The Research Team

### 11 Specialized Research Agents (5 NEW!)

#### Literature Specialists (NEW: Split into 3!)

**ğŸŒ Web Research Specialist (D. Freuzer)** - @research-assistant-web

- Live web content, blogs, documentation
- Industry perspectives and trends
- GitHub repositories and implementations
- Recent posts and tutorials
- **Tools:** WebSearch, WebFetch
- **Commands:** `*search`, `*fetch`, `*search-docs`, `*search-github`, `*track-trends`

**ğŸ“„ ArXiv Specialist (H. Zoppel)** - @research-assistant-arxiv

- Academic pre-prints from arXiv
- Recent papers before peer review
- Author and category searches
- **MCP-Dependent:** Requires ArXiv MCP (gracefully fails if unavailable)
- **Tools:** ArXiv MCP (mcp**arxiv**search, mcp**arxiv**get_paper)
- **Commands:** `*search`, `*search-author`, `*search-category`, `*get-paper`

**ğŸ“š Knowledge Base Curator (A. Pilz)** - @research-assistant-kb

- Curated project knowledge base
- Tagged paper organization
- Full-text paper analysis
- Gap identification
- **Tools:** Archon MCP (rag_search_knowledge_base, rag_search_code_examples)
- **Commands:** `*set-tag`, `*sources`, `*search`, `*search-codes`, `*catalogue-paper`

#### Team Coordination

**ğŸ”¬ Research Lead (Prof. Dr. Kunz)** - @research-lead

- Team orchestration and coordination
- Literature search routing (directs D. Freuzer, H. Zoppel, A. Pilz)
- Research strategy and objectives
- Proposal development and validation
- Cross-agent synthesis
- Full project visibility (codebase/, results/, research-paper/)
- **Commands:** `*brainstorm`, `*create-proposal`, `*literature-review`, `*formulate-questions`

#### Experiment Team

**ğŸ§ª Research Scientist (Dr. Alex Kumar)** - @research-scientist

- Experimental design and methodology
- Works with Research Lead to construct experiments
- Creates specifications for PM/Architect â†’ ML Engineer pipeline
- Interprets results and refines experiments
- **Reads:** codebase/, results/
- **Commands:** `*create-architecture`, `*design-experiment`, `*interpret-results`

**âš™ï¸ ML Engineer (Jordan Lee)** - @ml-engineer

- Code implementation in **codebase/** folder
- Receives tasks from PM/Architect (BMAD core workflows)
- Implements experiments, baselines, novel methods
- **Weights & Biases (wandb) integration:** Tracks all experiments, logs metrics, saves artifacts
- Runs experiments, outputs to results/
- **Primary workspace:** codebase/
- **Commands:** `*implement-experiment`, `*implement-baseline`, `*setup-wandb`, `*track-experiment`, `*export-wandb-results`

**ğŸ“Š Data Analyst (Dr. Maya Patel)** - @data-analyst

- Dataset preparation in **codebase/data/**
- **wandb MCP integration:** Fetches experiment data directly from wandb for analysis
- Statistical analysis and visualization
- Creates publication-quality figures in **results/**
- Significance testing and error analysis
- **Workspaces:** codebase/data/, results/
- **MCP Tools:** mcp**wandb**query_wandb_tool, mcp**wandb**create_wandb_report_tool
- **Commands:** `*prepare-dataset`, `*analyze-results`, `*fetch-wandb-data`, `*compare-wandb-runs`, `*create-wandb-figures`

#### Publication Team

**âœï¸ Research Writer (Dr. Gatsby Sarihuela)** - @research-writer

- Paper writing in **research-paper/** folder
- LaTeX editing and formatting
- Git/Overleaf synchronization
- Incorporates results/ into paper
- **Venue-specific reformatting:** NeurIPS, ICML, IEEE, ACM, JMLR templates
- **Submission preparation:** Anonymization, supplementary materials, packaging
- **Primary workspace:** research-paper/
- **Tools:** LaTeX, git
- **Commands:** `*create-paper`, `*draft-abstract`, `*prepare-submission`, `*reformat-template`, `*anonymize`, `*package-submission`

**ğŸ” Reproducibility Engineer (Sam Rodriguez)** - @reproducibility-engineer

- Cross-folder validation (codebase/ â†’ results/ â†’ research-paper/)
- Ensures experiments are reproducible
- Code release preparation
- Documentation and containerization
- **Validates:** All folders
- **Commands:** `*verify-reproducibility`, `*prepare-release`, `*create-dockerfile`

## Complete Research Workflow - ITERATIVE & MANUAL

**CRITICAL: All phases can be invoked manually and repeated as needed!**

Research is inherently iterative. You may:

- Run Phase 1 multiple times as questions evolve
- Run Phase 2 many times with different experiments
- Return to Phase 1 after Phase 2 results suggest new directions
- Update the paper (Phase 3) continuously throughout the process
- Iterate between phases in any order based on findings

**The workflow below shows the typical flow, but YOU control when to invoke each phase.**

### ğŸ”„ Iterative Research Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ITERATIVE RESEARCH LOOP                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Phase 1: Planning â”€â”€â”€â”€â”                                    â”‚
â”‚  (Literature + Brainstorming)                                â”‚
â”‚           â”‚            â”‚                                     â”‚
â”‚           â†“            â”‚                                     â”‚
â”‚  Phase 2: Experiments â”€â”¤ â† Results may trigger              â”‚
â”‚  (Implementation + Analysis) new questions                   â”‚
â”‚           â”‚            â”‚                                     â”‚
â”‚           â†“            â”‚                                     â”‚
â”‚  Phase 3: Paper Update â”˜ â† Update paper after each cycle    â”‚
â”‚  (Continuous writing)                                        â”‚
â”‚           â”‚                                                  â”‚
â”‚           â†“                                                  â”‚
â”‚  REPEAT until ready for Phase 4                             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 4: Publication (Run once at the end)
```

**Key Insight:** The paper (Phase 3) should be updated after EVERY experiment iteration, not just at the end!

### ğŸ“ Folder Structure

All research artifacts are organized into three main folders:

```
your-research-project/
â”œâ”€â”€ codebase/              # ML Engineer's primary workspace
â”‚   â”œâ”€â”€ data/              # Datasets (Data Analyst + ML Engineer)
â”‚   â”œâ”€â”€ src/               # Experiment code
â”‚   â”œâ”€â”€ configs/           # Hyperparameters
â”‚   â”œâ”€â”€ tests/             # Unit tests
â”‚   â””â”€â”€ README.md          # Setup & reproduction guide
â”‚
â”œâ”€â”€ results/               # Data Analyst's primary output
â”‚   â”œâ”€â”€ figures/           # Publication-quality visualizations
â”‚   â”œâ”€â”€ tables/            # LaTeX-formatted tables
â”‚   â”œâ”€â”€ analysis/          # Statistical test results
â”‚   â””â”€â”€ metrics/           # Experimental metrics
â”‚
â””â”€â”€ research-paper/        # Research Writer's workspace (LaTeX + git)
    â”œâ”€â”€ main.tex           # Main paper file
    â”œâ”€â”€ sections/          # Paper sections
    â”œâ”€â”€ figures/           # Figures copied from results/
    â”œâ”€â”€ references.bib     # Bibliography
    â””â”€â”€ .git/              # Git repository (syncs with Overleaf)
```

### Phase 1: Planning - THREE-SPECIALIST LITERATURE SYSTEM

**ğŸ” REPEATABLE:** Run this phase multiple times as your research questions evolve!

**ğŸ¤– Automated Execution:** Let Prof. Dr. Kunz (Research Lead) orchestrate the entire workflow!

```bash
@research-lead
*run-phase-1 "your research topic"
# Prof. Dr. Kunz will:
# 1. Read workflows/phase-1-planning.yaml
# 2. Execute all steps in sequence
# 3. Coordinate three specialists automatically
# 4. Handle iterations (2-4 cycles)
# 5. Create all output documents
```

**ğŸ“‹ Or use the workflow as a guide:** [phase-1-planning.yaml](workflows/phase-1-planning.yaml)

**Manual Invocation (if you prefer step-by-step control):**

```bash
# The Research Lead orchestrates this entire phase:
@research-lead
*brainstorm "your evolving topic"      # Step 1: Generate research questions
*formulate-questions                   # Step 2: Extract search keywords from brainstorming

# Research Lead then coordinates three specialists in parallel:
# (Search keywords constructed from brainstorming results)

@research-assistant-web
*search "{keywords from Research Lead}"  # Web + GitHub + Industry trends

@research-assistant-arxiv
*search "{keywords from Research Lead}"  # Academic papers (if MCP available)

@research-assistant-kb
*search "{keywords from Research Lead}"  # Curated knowledge base

# Research Lead synthesizes findings:
@research-lead
*literature-review                     # Synthesize all three sources
*formulate-questions                   # Refine questions based on gaps found

# ITERATE 2-4 times until questions converge
# Then create formal documents:
@research-lead
*create-proposal

@research-scientist
*create-architecture
```

**Workflow:**

```
Prof. Dr. Kunz (Research Lead)
   â”‚
   â”œâ”€â†’ Initial Brainstorming (10-20 questions)
   â”‚
   â”œâ”€â†’ PARALLEL LITERATURE SEARCH â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   â”œâ”€â†’ D. Freuzer (Web):    Blogs, docs, GitHub   â”‚
   â”‚   â”œâ”€â†’ H. Zoppel (ArXiv):   Academic pre-prints   â”‚  Iteration 1
   â”‚   â””â”€â†’ A. Pilz (KB):        Tagged knowledge base â”‚
   â”‚                                                    â”‚
   â”œâ”€â†’ Synthesize all findings                         â”‚
   â”‚                                                    â”‚
   â”œâ”€â†’ Refine research questions                       â”‚
   â”‚                                                    â”‚
   â””â”€â†’ DEEPER DIVE (targeted searches) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ REPEAT 2-4 iterations until converged
       â”‚
       â”œâ”€â†’ Identify Gaps & Novel Contributions
       â”‚
       â”œâ”€â†’ Create Research Proposal
       â”‚
       â””â”€â†’ Research Scientist: Experimental Architecture
           â”‚
           â””â”€â†’ Prof. Dr. Kunz: Validation
```

**Outputs:**

- `research-brainstorming-session-results.md` (Research Lead)
- `literature-review.md` (All 3 assistants' findings synthesized)
- `research-proposal.md` (Research Lead)
- `experimental-architecture.md` (Research Scientist)

**Key Innovation:** Three specialists cover all sources (web + academic + curated) in parallel!

**When to Re-run Phase 1:**

- After Phase 2 experiments reveal unexpected results
- When you discover new related work during writing
- If reviewer feedback suggests missing literature
- When pivoting research direction

### Phase 2: Experimentation - EXPERIMENT PLANNING & ITERATION

**ğŸ” HIGHLY ITERATIVE:** This phase will be run MANY times! Each experiment may suggest new experiments.

**ğŸ¤– Automated Execution:** Let Prof. Dr. Kunz orchestrate the experiment iteration!

```bash
@research-lead
*run-phase-2 "test hypothesis X"
# Prof. Dr. Kunz will:
# 1. Coordinate Research Scientist to design experiment
# 2. Coordinate Experiment PM to plan development
# 3. Coordinate Experiment Architect to design code structure
# 4. Coordinate ML Engineer to implement and run experiments
# 5. Coordinate Data Analyst to analyze results
# 6. Present decision point: What next?
```

**ğŸ“‹ Or use the workflow as a guide:** [phase-2-single-experiment.yaml](workflows/phase-2-single-experiment.yaml)

**Manual Invocation (if you prefer step-by-step control):**

```bash
# Design a new experiment
@research-scientist
*design-experiment "test hypothesis X"

# Plan development
@experiment-pm
*plan-experiment

# Design architecture
@experiment-architect
*design-experiment-architecture

# Implement
@ml-engineer
*implement-experiment
*run-ablation

# Analyze results
@data-analyst
*analyze-results
*create-figures

# Interpret and decide next steps
@research-scientist
*interpret-results
# â†’ May trigger: new Phase 2 iteration OR back to Phase 1 OR update Phase 3
```

**Workflow:**

```
Research Scientist (Dr. Alex Kumar)
   â”‚
   â”œâ”€â†’ Design Experiment Specifications
   â”‚   â€¢ Methodology details
   â”‚   â€¢ Baselines to implement
   â”‚   â€¢ Evaluation metrics
   â”‚   â€¢ Success criteria
   â”‚
   â””â”€â†’ EXPERIMENT PLANNING WORKFLOW
       â”‚
       â”œâ”€â†’ Project Manager (@experiment-pm from bmad-ai-research)
       â”‚   â”‚
       â”‚   â”œâ”€â†’ Creates development plan
       â”‚   â”œâ”€â†’ Breaks down experiment into tasks
       â”‚   â”œâ”€â†’ Defines implementation milestones
       â”‚   â”‚
       â”‚   â””â”€â†’ Solution Architect (@experiment-architect from bmad-ai-research)
       â”‚       â”‚
       â”‚       â”œâ”€â†’ Designs code architecture
       â”‚       â”œâ”€â†’ Plans module structure (codebase/src/)
       â”‚       â”œâ”€â†’ Defines interfaces and APIs
       â”‚       â”‚
       â”‚       â””â”€â†’ ML Engineer (Jordan Lee - codebase/)
       â”‚           â”‚
       â”‚           â”œâ”€â†’ Implement experiment code
       â”‚           â”œâ”€â†’ Implement baselines
       â”‚           â”œâ”€â†’ Setup experiment tracking
       â”‚           â”‚
       â”‚           â””â”€â†’ Run experiments â†’ outputs to results/
       â”‚               â”‚
       â”‚               â””â”€â†’ Data Analyst (Dr. Maya Patel - results/)
       â”‚                   â”‚
       â”‚                   â”œâ”€â†’ Prepare datasets (codebase/data/)
       â”‚                   â”œâ”€â†’ Statistical analysis
       â”‚                   â”œâ”€â†’ Create figures (results/figures/)
       â”‚                   â”œâ”€â†’ Format tables (results/tables/)
       â”‚                   â”‚
       â”‚                   â””â”€â†’ Research Scientist: Interpret Results
       â”‚                       â”‚
       â”‚                       â””â”€â†’ If needed: Refine & iterate
```

**Experiment Planning Integration:**

- **Research Scientist** creates high-level experiment specs
- **PM** (from bmad-ai-research) plans development workflow
- **Architect** (from bmad-ai-research) designs implementation structure
- **ML Engineer** executes implementation

**Folder Flow:**

- Code lives in: `codebase/`
- Data lives in: `codebase/data/`
- Results output to: `results/`

**Outputs:**

- Development plan (PM)
- Architecture design (Architect)
- Experiment code (`codebase/`)
- Trained models (not version controlled)
- Analysis artifacts (`results/`)

**After Phase 2 Iteration:**

1. **ALWAYS update the paper** (go to Phase 3)
2. **Decide next step:**
   - Run another Phase 2 iteration (new experiment)
   - Return to Phase 1 (if results suggest new research direction)
   - Move toward Phase 4 (if results are sufficient)

### Phase 3: Writing - CONTINUOUS PAPER UPDATES

**ğŸ” CONTINUOUS:** Update paper after EVERY Phase 2 iteration, not just at the end!

**ğŸ¤– Automated Execution:** Let Prof. Dr. Kunz orchestrate paper updates!

```bash
# First time (create paper structure)
@research-lead
*run-phase-3 initial_setup

# After each experiment (most common)
@research-lead
*run-phase-3 incremental_update

# Every 4-6 weeks (major revision)
@research-lead
*run-phase-3 full_revision

# Before submission (final polish)
@research-lead
*run-phase-3 pre_submission_polish
```

**ğŸ“‹ Or use the workflow as a guide:** [phase-3-paper-update.yaml](workflows/phase-3-paper-update.yaml)

**Workflow Variants:**

- **initial_setup**: Run once to create paper structure
- **incremental_update**: Run after EVERY experiment (30 min - 2 hours)
- **full_revision**: Run every 4-6 weeks for major revision (1-2 days)
- **pre_submission_polish**: Run once before submission (2-5 days)

**Why Update Continuously:**

- Keeps paper aligned with latest results
- Prevents massive rewrites at submission time
- Helps you see gaps in experiments early
- Makes story clearer as research progresses

**Manual Invocation (or follow workflow):**

```bash
# Initial paper setup (run once)
@research-writer
*create-paper

# After EACH Phase 2 iteration, update relevant sections:
@research-writer
*draft-experiments    # Add new results
*draft-methodology    # Refine based on what you actually did
*draft-related-work   # Add newly discovered papers

# Sync with git/Overleaf
# git pull â†’ edit â†’ git commit â†’ git push

# Periodic full reviews
@research-lead
# Review entire paper, suggest improvements

@research-writer
*revise-paper
*prepare-submission  # When ready for submission
```

**Workflow:**

```
Research Writer (research-paper/)
   â”‚
   â”œâ”€â†’ git pull (sync from Overleaf)
   â”‚
   â”œâ”€â†’ Create Paper Outline (main.tex, sections/)
   â”‚
   â”œâ”€â†’ Copy figures from results/ â†’ research-paper/figures/
   â”‚
   â”œâ”€â†’ Draft All Sections
   â”‚   â”œâ”€â†’ Abstract
   â”‚   â”œâ”€â†’ Introduction
   â”‚   â”œâ”€â†’ Related Work (coordinate with A. Pilz for citations)
   â”‚   â”œâ”€â†’ Methodology (coordinate with Research Scientist)
   â”‚   â”œâ”€â†’ Experiments (incorporate from results/)
   â”‚   â””â”€â†’ Conclusion
   â”‚
   â”œâ”€â†’ git commit -m "Draft complete"
   â”œâ”€â†’ git push (sync to Overleaf)
   â”‚
   â”œâ”€â†’ Prof. Dr. Kunz: Review Draft
   â”‚
   â”œâ”€â†’ Research Writer: Revise & Polish
   â”‚
   â”œâ”€â†’ Format for Target Venue (NeurIPS/ICML/ICLR/etc.)
   â”‚
   â””â”€â†’ git push (final version synced)
```

**Folder Flow:**

- Paper lives in: `research-paper/`
- Reads figures from: `results/`
- Git syncs with: Overleaf

### Phase 4: Publication & Submission

**ğŸ” REPEATABLE:** Run for each venue you submit to (NeurIPS, ICML, IEEE, etc.)

**ğŸ¤– Automated Execution:** Let Research Writer handle venue-specific reformatting!

```bash
@research-writer
*prepare-submission "NeurIPS 2025"
# Research Writer will:
# 1. Read workflows/paper-submission-prep.yaml
# 2. Analyze venue requirements
# 3. Reformat LaTeX template
# 4. Adjust content for page limits
# 5. Prepare supplementary materials
# 6. Create submission package
```

**ğŸ“‹ Or use the workflow as a guide:** [paper-submission-prep.yaml](workflows/paper-submission-prep.yaml)

**What This Phase Handles:**

- **Venue-specific formatting:** Switch LaTeX templates (NeurIPS, ICML, IEEE, ACM, JMLR)
- **Page limit adjustment:** Move content to appendix, condense sections
- **Citation style conversion:** natbib, IEEE numeric, ACM format
- **Anonymization:** Remove author info for double-blind review
- **Supplementary materials:** Package code, data, extra results
- **Submission packaging:** Create final PDFs, source files, supplementary ZIP
- **Verification:** Compilation checks, submission checklists

**Manual Invocation:**

```bash
# Step 1: Analyze target venue
@research-writer
*analyze-venue "NeurIPS 2025"
# Creates: docs/submission/venue-requirements.md

# Step 2: Create submission branch
git checkout -b submission/neurips-2025

# Step 3: Reformat for venue
@research-writer
*reformat-template "neurips_2025"
*trim-to-limit "8 pages"
*convert-citations "natbib"
*anonymize  # If required

# Step 4: Prepare supplementary materials
@reproducibility-engineer
*prepare-release  # Clean and package code

@research-writer
*prepare-supplementary

# Step 5: Final compilation and packaging
@research-writer
*compile-submission
*create-checklist "NeurIPS 2025"
*package-submission
```

**Workflow:**

```
Research Writer
   â”‚
   â”œâ”€â†’ Analyze Venue Requirements
   â”‚   â””â”€â†’ Create docs/submission/venue-requirements.md
   â”‚
   â”œâ”€â†’ Create Submission Branch (git)
   â”‚
   â”œâ”€â†’ Switch LaTeX Template
   â”‚   â”œâ”€â†’ NeurIPS: neurips_2025.sty
   â”‚   â”œâ”€â†’ ICML: icml2025.sty
   â”‚   â”œâ”€â†’ IEEE: IEEEtran.cls
   â”‚   â””â”€â†’ ACM: acmart.cls
   â”‚
   â”œâ”€â†’ Adjust Content for Page Limit
   â”‚   â”œâ”€â†’ Move methods to appendix
   â”‚   â”œâ”€â†’ Move extra results to appendix
   â”‚   â””â”€â†’ Condense verbose sections
   â”‚
   â”œâ”€â†’ Reformat Figures & Tables
   â”‚   â””â”€â†’ Data Analyst: Adjust sizes for venue
   â”‚
   â”œâ”€â†’ Convert Citation Style
   â”‚
   â”œâ”€â†’ Anonymize (if required)
   â”‚   â”œâ”€â†’ Remove author names
   â”‚   â”œâ”€â†’ Remove affiliations
   â”‚   â””â”€â†’ Anonymize self-citations
   â”‚
   â”œâ”€â†’ Prepare Supplementary Materials
   â”‚   â”œâ”€â†’ Code package (Reproducibility Engineer)
   â”‚   â”œâ”€â†’ Appendix PDF
   â”‚   â”œâ”€â†’ Extra results
   â”‚   â””â”€â†’ Dataset information
   â”‚
   â”œâ”€â†’ Final Compilation & Verification
   â”‚   â”œâ”€â†’ Clean LaTeX build
   â”‚   â”œâ”€â†’ Check page count
   â”‚   â”œâ”€â†’ Verify all figures
   â”‚   â””â”€â†’ Check PDF metadata
   â”‚
   â”œâ”€â†’ Generate Submission Checklist
   â”‚   â””â”€â†’ docs/submission/neurips-2025-checklist.md
   â”‚
   â””â”€â†’ Create Submission Package
       â”œâ”€â†’ Paper1234.pdf (main paper)
       â”œâ”€â†’ Paper1234-source.zip (LaTeX source)
       â””â”€â†’ Paper1234-supp.zip (supplementary)
```

**Supported Venues:**

- **ML Conferences:** NeurIPS, ICML, ICLR, AAAI, CVPR
- **Journals:** JMLR, TMLR, IEEE TPAMI
- **IEEE Conferences:** Template-based formatting
- **ACM Conferences:** sigconf template

**Outputs:**

- `submissions/{venue}-{date}/` - Complete submission package
- `docs/submission/venue-requirements.md` - Venue analysis
- `docs/submission/{venue}-checklist.md` - Pre-submission verification

**Revision & Rebuttal Workflow** (after reviews):

```bash
@research-writer
*process-reviews  # Parse reviewer comments
*apply-revisions  # Update paper based on feedback
*write-rebuttal   # Draft response to reviewers
```

**Outputs:**

- Complete LaTeX paper (`research-paper/`)
- Continuously updated sections
- Submission-ready PDF (when ready)

**Paper Evolution:**

- **Early:** Draft outline, intro, related work
- **Mid-research:** Growing experiments section, refined methodology
- **Late-research:** Complete draft with all results
- **Pre-submission:** Polished, formatted for venue

### Phase 4: Publication - FINAL VALIDATION & SUBMISSION

**ğŸ¯ RUN ONCE:** Only when paper is complete and ready to submit!

**Manual Invocation:**

```bash
# Validate everything works
@reproducibility-engineer
*verify-reproducibility  # Can codebase/ reproduce results/?
*prepare-release        # Clean code for public release
*create-dockerfile      # Containerization

# Final checks
@research-lead
# Review entire pipeline: codebase/ â†’ results/ â†’ research-paper/
# Ensure story is coherent and claims are supported

@data-analyst
*test-significance  # Final statistical checks

@research-writer
*prepare-submission  # Format for target venue
*draft-abstract     # Final abstract polish

# Submit!
# â†’ Upload paper to conference/journal
# â†’ Release code on GitHub
```

**Workflow:**

```
Reproducibility Engineer
   â”‚
   â”œâ”€â†’ Validate codebase/
   â”‚   â”œâ”€â†’ Check seeds, dependencies, README
   â”‚   â””â”€â†’ Verify experiments can be re-run
   â”‚
   â”œâ”€â†’ Validate results/
   â”‚   â””â”€â†’ Confirm figures/metrics match paper claims
   â”‚
   â”œâ”€â†’ Validate research-paper/
   â”‚   â””â”€â†’ Ensure all claims backed by results/
   â”‚
   â”œâ”€â†’ Create Documentation
   â”‚   â”œâ”€â†’ codebase/README.md
   â”‚   â”œâ”€â†’ codebase/REPRODUCE.md
   â”‚   â””â”€â†’ Dockerfile/environment.yml
   â”‚
   â”œâ”€â†’ Prepare Code Release
   â”‚   â”œâ”€â†’ Clean codebase/ for public
   â”‚   â”œâ”€â†’ Add LICENSE
   â”‚   â””â”€â†’ Remove sensitive data
   â”‚
   â””â”€â†’ Prof. Dr. Kunz: Final Validation
       â”‚
       â””â”€â†’ SUBMIT to Conference/Journal
```

**Cross-Folder Validation:**

- `codebase/` â†’ Can reproduce â†’ `results/`
- `results/` â†’ Matches claims in â†’ `research-paper/`

**Outputs:**

- Submitted paper
- Public code repository (GitHub)
- Reproducibility artifacts

---

## ğŸ“Š Summary: Manual Phase Control

**The key insight of this workflow: YOU control the iteration!**

| Phase                        | Frequency          | When to Invoke                                                                                   |
| ---------------------------- | ------------------ | ------------------------------------------------------------------------------------------------ |
| **Phase 1: Planning**        | Multiple times     | Initial setup, after surprising results, when pivoting direction, during writing when gaps found |
| **Phase 2: Experimentation** | Many times (5-20+) | For each hypothesis, baseline, ablation, analysis. Most time spent here!                         |
| **Phase 3: Writing**         | Continuously       | After EVERY Phase 2 iteration. Keep paper in sync with research!                                 |
| **Phase 4: Publication**     | Once               | When paper is complete, experiments done, story clear, ready to submit                           |

**Typical Research Timeline:**

```
Week 1-2:   Phase 1 (initial)
Week 3-4:   Phase 2 iteration 1 â†’ Phase 3 update
Week 5:     Phase 2 iteration 2 â†’ Phase 3 update
Week 6:     Phase 1 (refine) + Phase 2 iteration 3 â†’ Phase 3 update
Week 7-10:  Phase 2 iterations 4-8 â†’ Phase 3 updates
Week 11:    Phase 1 (final literature check)
Week 12-14: Phase 2 final experiments â†’ Phase 3 major revision
Week 15:    Phase 4 (validation + submission)
```

**Remember:** The phases are guidelines, not prison! Jump between them as your research demands.

---

## Key Documents

### Research-Specific Templates

**Research Proposal** (`research-proposal-tmpl.yaml`)

- Problem statement and motivation
- Research questions and hypotheses
- Proposed approach
- Expected contributions
- Timeline and resources

**Experimental Architecture** (`experimental-architecture-tmpl.yaml`)

- Model architecture specifications
- Training procedures
- Baseline implementations
- Evaluation protocols
- Reproducibility specifications

**Paper Outline** (`paper-outline-tmpl.yaml`)

- Complete paper structure
- Section-by-section planning
- Figure and table planning
- Page budget allocation

**Experiment Specification** (`experiment-spec-tmpl.yaml`)

- Hypothesis to test
- Methodology details
- Implementation plan
- Success criteria
- Analysis approach

**Literature Review** (`literature-review-tmpl.yaml`)

- Thematic organization
- Key papers analysis
- Research gaps identification
- Positioning statement

**Reproducibility Checklist** (`reproducibility-checklist-tmpl.yaml`)

- Code reproducibility checks
- Environment setup validation
- Data pipeline verification
- Results validation

## Installation & Setup

### Step 1: Install Expansion Pack

**Option A: From Published Package (when available):**

```bash
cd your-project
npx bmad-method install
# Select "bmad-ai-research" when prompted
```

**Option B: Local Development (current):**

Since this expansion pack is in development and not yet published:

```bash
# 1. Clone or navigate to BMAD-METHOD repo
cd /path/to/BMAD-METHOD

# 2. Install in your project from local source
cd /path/to/your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select "bmad-ai-research" when prompted

# OR copy directly to your project
cp -r /path/to/BMAD-METHOD/expansion-packs/bmad-ai-research \
      /path/to/your-project/.bmad-ai-research
```

**Fresh research project:**

```bash
mkdir my-research-project && cd my-research-project
# Use one of the methods above
```

### Step 2: (Optional) Configure Archon MCP for Literature Search

If you want automated literature search via the Research Assistant:

1. **Ensure Archon MCP is running** in your IDE (should already be configured)
2. **Add research papers to knowledge base** with project-specific tags
3. **Use Research Assistant** with your project tag:

```bash
@research-assistant
*set-tag "ml-research"     # Your project tag
*sources                   # List available sources
*search "attention mechanisms"  # Search papers
```

**No Archon MCP?** The Research Assistant will guide you to manual literature searches instead.

### Step 3: Start Your First Research Project

```bash
# 1. Brainstorm research questions
@research-lead
*brainstorm "your research topic"

# 2. Search literature (if Archon MCP available)
@research-assistant
*search "relevant keywords"

# 3. Iterate until converged (2-4 cycles)

# 4. Create proposal
@research-lead
*create-proposal
```

**ğŸ“– Full setup guide:** [SETUP-CHECKLIST.md](SETUP-CHECKLIST.md)

## Usage Examples

### Starting a New Research Project (Three-Specialist System)

```bash
# Step 1: Brainstorm initial questions
@research-lead
*brainstorm "efficient attention mechanisms for transformers"
# â†’ Prof. Dr. Kunz generates 10-20 research questions

# Step 2: Parallel literature search (all three specialists)
# The Research Lead coordinates this, but you can also invoke directly:

@research-assistant-web      # D. Freuzer
*search "efficient attention mechanisms 2024"
# â†’ Searches blogs, documentation, GitHub
# â†’ Finds: HuggingFace blog posts, PyTorch tutorials, recent implementations

@research-assistant-arxiv    # H. Zoppel (if MCP available)
*search "efficient attention transformers"
# â†’ Searches arXiv pre-prints
# â†’ Finds: FlashAttention-3, recent academic papers

@research-assistant-kb       # A. Pilz
*set-tag "transformer-research"
*search "attention mechanisms"
# â†’ Searches your curated knowledge base
# â†’ Finds: Tagged papers in your project corpus

# Step 3: Prof. Dr. Kunz synthesizes all findings
@research-lead
*formulate-questions
# â†’ Refines questions based on gaps from ALL THREE sources

# Step 4: Deeper targeted dive (iteration 2)
@research-assistant-web
*search-github "flash attention implementation"

@research-assistant-arxiv
*search-author "Dao"  # FlashAttention author

@research-assistant-kb
*identify-gaps
# â†’ What's missing from KB that should be added?

# Repeat iterations 2-4 times until converged

# Step 5: Create formal proposal
@research-lead
*create-proposal
# â†’ Creates research-proposal.yaml

# Step 6: Design experiments
@research-scientist
*create-architecture
*design-experiment
# â†’ Creates detailed experiment specifications
```

### Running Experiments (with BMAD Core PM/Architect)

```bash
# Step 1: Prepare data
@data-analyst
*prepare-dataset
# â†’ Processes data in codebase/data/
# â†’ Validates and documents datasets

# Step 2: Development Planning (BMAD Core Workflow)
@experiment-pm  # From bmad-core package
# Takes Research Scientist's experiment specs
# â†’ Creates development plan
# â†’ Breaks down into implementation tasks
# â†’ Defines milestones

@experiment-architect  # From bmad-core package
# Takes PM's development plan
# â†’ Designs code architecture
# â†’ Plans codebase/src/ module structure
# â†’ Defines interfaces and data flow

# Step 3: Implementation (codebase/)
@ml-engineer
*implement-experiment
# â†’ Follows Architect's design
# â†’ Writes code in codebase/src/
# â†’ Implements experiment logic

*implement-baseline
# â†’ Codes baseline methods

*setup-tracking
# â†’ wandb/tensorboard integration

# Step 4: Execute experiments
@ml-engineer
*run-ablation
# â†’ Runs experiments with proper seeds
# â†’ Outputs metrics/logs to results/

# Step 4: Analyze results (results/)
@data-analyst
*analyze-results
# â†’ Reads from results/, performs statistical tests
# â†’ Creates figures in results/figures/
# â†’ Formats tables in results/tables/

*create-figures
# â†’ Publication-quality plots (300 DPI, LaTeX fonts)

# Step 5: Interpret findings
@research-scientist
*interpret-results
# â†’ Analyzes results/ against hypotheses
# â†’ Suggests refinements if needed
```

### Writing Paper (research-paper/ with LaTeX + git)

```bash
# Step 1: Setup paper folder
@research-writer
# â†’ git pull (sync from Overleaf if already exists)
*create-paper
# â†’ Creates main.tex, sections/, references.bib in research-paper/

# Step 2: Copy figures from results/
# â†’ Manually or via Research Writer:
# cp results/figures/* research-paper/figures/

# Step 3: Draft sections (all in research-paper/)
@research-writer
*draft-abstract
# â†’ Writes abstract in sections/abstract.tex

*draft-introduction
# â†’ Includes motivation, contributions

*draft-related-work
# â†’ Coordinates with @research-assistant-kb (A. Pilz) for citations

*draft-methodology
# â†’ Coordinates with @research-scientist for technical details

*draft-experiments
# â†’ Incorporates results/ (figures, tables, metrics)

*draft-conclusion
# â†’ Summary, impact, future work

# Step 4: Git sync
# â†’ Research Writer commits and pushes
# git add . && git commit -m "Complete draft" && git push
# â†’ Syncs to Overleaf automatically

# Step 5: Review
@research-lead
# â†’ Prof. Dr. Kunz reviews on Overleaf
# â†’ Provides feedback

# Step 6: Revise and submit
@research-writer
# â†’ git pull (get latest from Overleaf)
*revise-paper
*prepare-submission
# â†’ Formats for NeurIPS/ICML/ICLR/etc.
# git push (final version)
```

### Preparing Code Release (Cross-folder validation)

```bash
@reproducibility-engineer

# Step 1: Validate codebase/
*verify-reproducibility
# â†’ Check seeds set correctly
# â†’ Verify requirements.txt/environment.yml complete
# â†’ Test that codebase/ experiments can be re-run
# â†’ Ensure codebase/README.md is comprehensive

# Step 2: Validate results/
# â†’ Confirm figures match paper claims
# â†’ Check metrics in results/ match research-paper/
# â†’ Verify all paper figures came from results/

# Step 3: Validate research-paper/
# â†’ Ensure all claims backed by results/
# â†’ Check figure numbers match
# â†’ Verify no orphaned claims

# Step 4: Create documentation
*create-readme
# â†’ Generates codebase/README.md
# â†’ Creates codebase/REPRODUCE.md (step-by-step guide)

*create-dockerfile
# â†’ Docker/Singularity for reproducibility

# Step 5: Prepare for public release
*prepare-release
# â†’ Clean codebase/ (remove secrets, internal paths)
# â†’ Add LICENSE file
# â†’ Prepare GitHub repository
# â†’ Final validation: can a stranger reproduce results/?

# Step 6: Final sign-off
# â†’ Prof. Dr. Kunz reviews all three folders
# â†’ Submits paper + code
```

## Best Practices

### Reproducibility First

- Set all random seeds from day one
- Version control everything (code, configs, not models)
- Document as you go, not retrospectively
- Use experiment tracking (wandb, tensorboard)

### Embrace Failure

- Most experiments fail - that's research
- Failed experiments teach what doesn't work
- Document failures to avoid repeating them
- Pivot based on what you learn

### Statistical Rigor

- Always run multiple seeds (3-5 minimum)
- Report mean Â± standard deviation
- Perform significance testing
- Compare fairly against strong baselines

### Honest Science

- Report what you find, not what you hoped
- Acknowledge limitations explicitly
- Give proper credit to related work
- Don't cherry-pick favorable results

## Typical Timeline

- **Planning Phase:** 1-2 weeks
- **Implementation:** 2-4 weeks
- **Experimentation:** 2-6+ weeks (variable!)
- **Analysis:** 1-2 weeks
- **Writing:** 2-4 weeks
- **Revision (if needed):** 1-4 weeks

**Total:** 3-6 months for conference paper

## Target Venues

This pack helps you prepare papers for:

**Top ML Conferences:**

- NeurIPS, ICML, ICLR

**Top Vision Conferences:**

- CVPR, ICCV, ECCV

**Top NLP Conferences:**

- ACL, EMNLP, NAACL

**And many others** (specialized venues for robotics, data mining, etc.)

## What's Included

### ğŸ“ Directory Structure

```
bmad-ai-research/
â”œâ”€â”€ agents/                 # 9 specialized research agents (3 NEW!)
â”‚   â”œâ”€â”€ research-lead.md                    # Prof. Dr. Kunz (team coordinator)
â”‚   â”œâ”€â”€ research-assistant-web.md           # NEW! D. Freuzer (web research)
â”‚   â”œâ”€â”€ research-assistant-arxiv.md         # NEW! H. Zoppel (arXiv papers)
â”‚   â”œâ”€â”€ research-assistant-kb.md            # NEW! A. Pilz (knowledge base)
â”‚   â”œâ”€â”€ research-scientist.md               # Dr. Alex Kumar (experiment design)
â”‚   â”œâ”€â”€ ml-engineer.md                      # Jordan Lee (codebase/ implementation)
â”‚   â”œâ”€â”€ data-analyst.md                     # Dr. Maya Patel (results/ analysis)
â”‚   â”œâ”€â”€ research-writer.md                  # Dr. Gatsby Sarihuela (research-paper/ writing)
â”‚   â””â”€â”€ reproducibility-engineer.md         # Sam Rodriguez (validation)
â”œâ”€â”€ agent-teams/           # Pre-configured research team
â”‚   â””â”€â”€ research-team.yaml                  # UPDATED: 3 literature specialists
â”œâ”€â”€ templates/             # 6 research document templates
â”œâ”€â”€ workflows/             # 2 complete research workflows
â”œâ”€â”€ tasks/                 # 3 research-specific tasks
â”œâ”€â”€ checklists/            # Implementation & reproducibility checklists
â”œâ”€â”€ data/                  # Research knowledge base
â”œâ”€â”€ docs/                  # Setup and integration guides
â”‚   â”œâ”€â”€ ARCHON-MCP-INTEGRATION.md
â”‚   â””â”€â”€ ITERATIVE-RESEARCH-WORKFLOW.md
â””â”€â”€ config.yaml            # Pack configuration
```

### ğŸ¯ Key Features

**ğŸ†• NEW IN THIS VERSION:**

- **Three-Specialist Literature System**: Web (D. Freuzer) + ArXiv (H. Zoppel) + KB (A. Pilz) working in parallel
- **Comprehensive Source Coverage**: Industry trends + Academic papers + Curated corpus
- **Folder-Based Workflow**: Organized structure (codebase/, results/, research-paper/)
- **BMAD Core Integration**: Full workflow with Project Manager + Solution Architect
  - Research Scientist designs experiments
  - PM (bmad-core) plans development
  - Architect (bmad-core) designs implementation
  - ML Engineer executes in codebase/
- **LaTeX + Git + Overleaf**: Professional paper writing with version control
- **Cross-Folder Validation**: Reproducibility Engineer ensures pipeline integrity

**CORE FEATURES:**

- **Iterative Brainstorming**: Proven 2-4 cycle loop between ideation and literature
- **Hypothesis-Focused**: Every experiment tests specific hypotheses
- **Reproducibility-First**: Comprehensive reproducibility infrastructure
- **Publication-Ready**: Templates match conference/journal requirements
- **Statistically Rigorous**: Built-in statistical testing guidance
- **Peer Review Aware**: Anticipates reviewer concerns
- **Team Coordination**: Prof. Dr. Kunz orchestrates entire research team

## Documentation

- **ğŸ“š Setup Guide**: [SETUP-CHECKLIST.md](SETUP-CHECKLIST.md) - Complete installation and setup
- **ğŸ”— Archon MCP Integration**: [docs/ARCHON-MCP-INTEGRATION.md](docs/ARCHON-MCP-INTEGRATION.md) - Literature search setup
- **ğŸ”„ Iterative Workflow**: [docs/ITERATIVE-RESEARCH-WORKFLOW.md](docs/ITERATIVE-RESEARCH-WORKFLOW.md) - Brainstorm-literature loop
- **ğŸ“– Research Knowledge Base**: [data/research-kb.md](data/research-kb.md) - Best practices guide
- **âš™ï¸ Full Workflow**: [workflows/research-paper-full.yaml](workflows/research-paper-full.yaml) - End-to-end process
- **ğŸ”¬ Experiment Iteration**: [workflows/experiment-iteration.yaml](workflows/experiment-iteration.yaml) - Focused experiment cycle

## Differences from Core BMAD

| Core BMAD                       | AI Research Pack                                                        |
| ------------------------------- | ----------------------------------------------------------------------- |
| PRD                             | Research Proposal                                                       |
| Architecture                    | Experimental Architecture                                               |
| User Stories                    | Experiment Specifications                                               |
| **PM/Architect plan features**  | **Research Scientist â†’ PM/Architect â†’ ML Engineer** (fully autonomous!) |
| Dev implements features         | ML Engineer implements experiments                                      |
| QA checks functionality         | Reproducibility Engineer checks reproducibility                         |
| Product release                 | Paper publication + code release                                        |
| Single codebase                 | Three folders: codebase/, results/, research-paper/                     |
| 1 generalist research assistant | 3 specialist research assistants (Web, ArXiv, KB)                       |

## Common Research Pitfalls Avoided

âœ… **Fair baseline comparisons** - Templates enforce equal tuning effort
âœ… **Statistical significance** - Built-in significance testing
âœ… **Reproducibility** - Comprehensive checklists from day one
âœ… **Clear contributions** - Structured proposal and paper templates
âœ… **Honest limitations** - Templates prompt for limitation discussion
âœ… **Proper attribution** - Literature review integrated throughout

## Success Stories

Research conducted with structured workflows like this:

- Higher acceptance rates (fewer desk rejects)
- Faster iteration (clear experiment specifications)
- Better reproducibility (checklist-driven development)
- Easier collaboration (standardized documents)
- Reduced reviewer concerns (comprehensive methodology)

## Contributing

Found a bug? Have suggestions? Want to add features?

- Open an issue in the main BMAD repository
- Contribute research-specific improvements
- Share your published papers using this pack!

## License

MIT License - Same as core BMAD-METHOD

## Acknowledgments

Built on the BMAD-METHODâ„¢ framework by BMad Code, LLC.

Designed for researchers who want to:

- Conduct rigorous, reproducible research
- Navigate the publication process systematically
- Collaborate effectively on research projects
- Advance their field with solid contributions

---

## Quick Links

- ğŸ“– [Setup Checklist](SETUP-CHECKLIST.md) - Get started in minutes
- ğŸ”— [Archon MCP Setup](docs/ARCHON-MCP-INTEGRATION.md) - Enable automated literature search
- ğŸ”„ [Iterative Workflow](docs/ITERATIVE-RESEARCH-WORKFLOW.md) - Master the brainstorm-literature loop
- âš¡ [Quick Reference](QUICK-FIX.md) - Common commands and patterns

---

**Ready to start your research journey?**

```bash
# Install the pack (local development)
cd /path/to/your-project
node /path/to/BMAD-METHOD/tools/installer/bin/bmad.js install
# Select: bmad-ai-research

# OR when published:
# npx bmad-method install
# Select: bmad-ai-research

# Start researching!
@research-lead
*brainstorm "your research topic"

# Parallel literature search (three specialists)
@research-assistant-web      # D. Freuzer: Web/blogs
*search "your topic 2024"

@research-assistant-arxiv    # H. Zoppel: ArXiv (if MCP available)
*search "your topic"

@research-assistant-kb       # A. Pilz: Knowledge base
*set-tag "your-project"
*search "your topic"
```

**Questions?**

- ğŸ“š Check the [research knowledge base](data/research-kb.md)
- ğŸ’¬ Join the [BMAD Discord](https://discord.gg/gk8jAdXWmj)
- ğŸ› Report issues on [GitHub](https://github.com/bmadcode/bmad-method/issues)

---

ğŸ”¬ **Good luck with your research!** ğŸ“ŠğŸ“

_Built with â¤ï¸ for researchers who want rigorous, reproducible, and publishable AI research._
